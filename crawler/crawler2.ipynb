{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pyperclip\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re  \n",
    "import math\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver=webdriver.Chrome()\n",
    "url='https://www.oliveyoung.co.kr/store/main/getBestList.do' #상품 랭킹 페이지\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "items=soup.select('.cate_prd_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.oliveyoung.co.kr/store/goods/getGoodsDetail.do?goodsNo=A000000211001&dispCatNo=90000010009&trackingCd=Best_Sellingbest&t_page=랭킹&t_click=판매랭킹_전체_상품상세&t_number=1'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[0].select('.prd_info')[0].select('.prd_thumb')[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_info=[]\n",
    "for i in range(len(items)):\n",
    "    tmp_list=items[i].select('.prd_info')\n",
    "    for j in range(len(tmp_list)):\n",
    "        product_name=items[i].select('.prd_info')[j].select('.tx_name')[0].text\n",
    "        product_url=items[i].select('.prd_info')[j].select('.prd_thumb')[0]['href']\n",
    "        product_info.append([product_name, product_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df=pd.DataFrame(product_info, columns=['product_name', 'product_url'])\n",
    "product_df['date']=datetime.today().strftime(\"%Y.%m.%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_url</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[10월 올영픽][JIN 미니포토북 선착순 증정] 라네즈 크림스킨 170ml 기획 ...</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/goods/getGo...</td>\n",
       "      <td>2024.10.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10월올영픽]에스트라 리제덤 365 모공탄력 캡슐세럼 30ml 기획 (+세럼15m...</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/goods/getGo...</td>\n",
       "      <td>2024.10.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[10월 올영픽] 아누아 복숭아 70 나이아신아마이드 세럼 30ml 더블기획</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/goods/getGo...</td>\n",
       "      <td>2024.10.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[10월올영픽/5번팩증정] 넘버즈인 5번 글루타치온씨 흔적 앰플 30ml 더블 기획...</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/goods/getGo...</td>\n",
       "      <td>2024.10.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[10월 올영픽/Lee콜라보] 이니스프리 레티놀 시카 흔적 앰플 30ml 기획</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/goods/getGo...</td>\n",
       "      <td>2024.10.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>브링그린 알로에99% 수딩젤 300ml+300ml 더블기획</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/goods/getGo...</td>\n",
       "      <td>2024.10.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>라로슈포제 시카플라스트 밤 B5+ 100ml 기획 (+3ml 추가증정)</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/goods/getGo...</td>\n",
       "      <td>2024.10.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[우민누 콜라보/10월 올영픽] 스카이보틀 퍼퓸 핸드크림 50ml 6종 택1</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/goods/getGo...</td>\n",
       "      <td>2024.10.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[10월 올영픽] 네이밍 플러피 파우더 블러쉬 11colors</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/goods/getGo...</td>\n",
       "      <td>2024.10.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[1&amp;1더블] 어노브 실크 오일 헤어 에센스 더블 기획세트 (70ml+70ml) 3...</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/goods/getGo...</td>\n",
       "      <td>2024.10.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         product_name  \\\n",
       "0   [10월 올영픽][JIN 미니포토북 선착순 증정] 라네즈 크림스킨 170ml 기획 ...   \n",
       "1   [10월올영픽]에스트라 리제덤 365 모공탄력 캡슐세럼 30ml 기획 (+세럼15m...   \n",
       "2          [10월 올영픽] 아누아 복숭아 70 나이아신아마이드 세럼 30ml 더블기획   \n",
       "3   [10월올영픽/5번팩증정] 넘버즈인 5번 글루타치온씨 흔적 앰플 30ml 더블 기획...   \n",
       "4         [10월 올영픽/Lee콜라보] 이니스프리 레티놀 시카 흔적 앰플 30ml 기획   \n",
       "..                                                ...   \n",
       "95                   브링그린 알로에99% 수딩젤 300ml+300ml 더블기획   \n",
       "96            라로슈포제 시카플라스트 밤 B5+ 100ml 기획 (+3ml 추가증정)   \n",
       "97         [우민누 콜라보/10월 올영픽] 스카이보틀 퍼퓸 핸드크림 50ml 6종 택1   \n",
       "98                 [10월 올영픽] 네이밍 플러피 파우더 블러쉬 11colors   \n",
       "99  [1&1더블] 어노브 실크 오일 헤어 에센스 더블 기획세트 (70ml+70ml) 3...   \n",
       "\n",
       "                                          product_url        date  \n",
       "0   https://www.oliveyoung.co.kr/store/goods/getGo...  2024.10.02  \n",
       "1   https://www.oliveyoung.co.kr/store/goods/getGo...  2024.10.02  \n",
       "2   https://www.oliveyoung.co.kr/store/goods/getGo...  2024.10.02  \n",
       "3   https://www.oliveyoung.co.kr/store/goods/getGo...  2024.10.02  \n",
       "4   https://www.oliveyoung.co.kr/store/goods/getGo...  2024.10.02  \n",
       "..                                                ...         ...  \n",
       "95  https://www.oliveyoung.co.kr/store/goods/getGo...  2024.10.02  \n",
       "96  https://www.oliveyoung.co.kr/store/goods/getGo...  2024.10.02  \n",
       "97  https://www.oliveyoung.co.kr/store/goods/getGo...  2024.10.02  \n",
       "98  https://www.oliveyoung.co.kr/store/goods/getGo...  2024.10.02  \n",
       "99  https://www.oliveyoung.co.kr/store/goods/getGo...  2024.10.02  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def real_crawling():\n",
    "    tmp_list=[]\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    for a in range(len(soup.select('.inner_list>li'))):\n",
    "        user_name=soup.select('.inner_list>li')[a].select('.info_user>.id')[0].text\n",
    "        user_key=soup.select('.inner_list>li')[a].select('.user.clrfix>a')[0]['onclick'].split(\"'\")[1]\n",
    "        user_url='https://www.oliveyoung.co.kr/store/mypage/getReviewerProfile.do?key=' + user_key\n",
    "#        review_point=soup.select('.inner_list>li')[a].select('.point')[0].text.split(' ')[-1]\n",
    " #       review_date=soup.select('.inner_list>li')[a].select('.date')[0].text\n",
    "  #      review_text=soup.select('.inner_list>li')[a].select('.txt_inner')[0].text\n",
    "   #     buy_type = soup.select('.inner_list>li')[a].select('.ico_gift')[0].text\n",
    "    #    review_referral=soup.select('.inner_list>li')[a].select('.num')[0].text.strip() \n",
    "        tmp_list.append([user_name, user_url])\n",
    "    return tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling(product_df):\n",
    "    product_review_df=pd.DataFrame()\n",
    "    driver.find_element(By.ID, 'searchType_3'.click())\n",
    "    time.sleep(1)\n",
    "    \n",
    "    for d in tqdm(range(len(product_df))):\n",
    "        product_name=product_df.iloc[d]['product_name']\n",
    "        url=product_df.iloc[d]['product_url']\n",
    "        driver.get(url)\n",
    "        time.sleep(1)\n",
    "\n",
    "        # 리뷰 버튼 클릭\n",
    "        driver.find_element(By.ID, value=\"reviewInfo\").click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        driver.find_element(By.ID, 'searchType_3'.click())\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # 리뷰 수 저장\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        review_cnt=int(soup.select('.goods_reputation')[0].text.split('(')[1].split(')')[0].replace(',', ''))\n",
    "        \n",
    "        # 상품별 리뷰 추출\n",
    "        review_list=[]\n",
    "        if review_cnt==0:\n",
    "            pass\n",
    "        \n",
    "        elif review_cnt>=1000:\n",
    "            for j in range(0, 9):\n",
    "                if j == 0: # 우선 첫페이지 (1)에 대해 크롤링 (1~10페이지)\n",
    "                    # 2페이지부터 다음페이지까지 클릭하면서 각 페이지크롤링\n",
    "                    for i in range(1, 11):\n",
    "                        tmp_list=real_crawling()\n",
    "                        review_list.extend(tmp_list)\n",
    "                        time.sleep(1)\n",
    "                        try:\n",
    "                            try: # 제품마다 xpath값에 차이가 있어서 구분함\n",
    "                                page_box = driver.find_element(By.XPATH,'//*[@id=\"gdasContentsArea\"]/div/div[7]/'+'a['+str(i)+']')\n",
    "                            except:\n",
    "                                page_box = driver.find_element(By.XPATH,'//*[@id=\"gdasContentsArea\"]/div/div[8]/'+'a['+str(i)+']')\n",
    "                            page_box.click()\n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "                        \n",
    "                elif j !=  9: #첫 페이지, 마지막 페이지가 아닌 경우 (페이지 11 이후)\n",
    "                    for i in range(2, 12):\n",
    "                        tmp_list=real_crawling()\n",
    "                        review_list.extend(tmp_list)\n",
    "                        time.sleep(1)\n",
    "                        try:\n",
    "                            try:\n",
    "                                page_box = driver.find_element(By.XPATH,'//*[@id=\"gdasContentsArea\"]/div/div[7]/'+'a['+str(i)+']')\n",
    "                            except:\n",
    "                                page_box = driver.find_element(By.XPATH,'//*[@id=\"gdasContentsArea\"]/div/div[8]/'+'a['+str(i)+']')\n",
    "                            page_box.click()\n",
    "                        except:\n",
    "                            pass\n",
    "                \n",
    "                else: # 마지막페이지의 경우 (넘어가기 인덱스 삭제)\n",
    "                    for i in range(2, 11):\n",
    "                        tmp_list=real_crawling()\n",
    "                        review_list.extend(tmp_list)\n",
    "                        time.sleep(1)\n",
    "                        try:\n",
    "                            if i!=10:\n",
    "                                try: # 제품마다 xpath값에 차이가 있어서 구분함\n",
    "                                    page_box = driver.find_element(By.XPATH,'//*[@id=\"gdasContentsArea\"]/div/div[7]/'+'a['+str(i)+']')\n",
    "                                except:\n",
    "                                    page_box = driver.find_element(By.XPATH,'//*[@id=\"gdasContentsArea\"]/div/div[8]/'+'a['+str(i)+']')\n",
    "                                page_box.click()      \n",
    "                        except:\n",
    "                            pass\n",
    "                       \n",
    "        else:\n",
    "            page_limit=math.ceil(review_cnt/10)\n",
    "            next_page_cnt=page_limit//10\n",
    "            for j in range(0, next_page_cnt+1):\n",
    "                if j == 0: # 우선 첫페이지 (1)에 대해 크롤링\n",
    "                    # 2페이지부터 다음페이지까지 클릭하면서 각 페이지크롤링\n",
    "                    for i in range(1, 11):\n",
    "                        tmp_list=real_crawling()\n",
    "                        review_list.extend(tmp_list)\n",
    "                        time.sleep(1)\n",
    "                        try:\n",
    "                            try: # 제품마다 xpath값에 차이가 있어서 구분함\n",
    "                                page_box = driver.find_element(By.XPATH,'//*[@id=\"gdasContentsArea\"]/div/div[7]/'+'a['+str(i)+']')\n",
    "                            except:\n",
    "                                page_box = driver.find_element(By.XPATH,'//*[@id=\"gdasContentsArea\"]/div/div[8]/'+'a['+str(i)+']')\n",
    "                            page_box.click()\n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "                        \n",
    "                elif j !=  next_page_cnt: #첫 페이지, 마지막 페이지가 아닌 경우 (페이지 11 이후)\n",
    "                    for i in range(2, 12):\n",
    "                        tmp_list=real_crawling()\n",
    "                        review_list.extend(tmp_list)\n",
    "                        time.sleep(1)\n",
    "                        try:\n",
    "                            try:\n",
    "                                page_box = driver.find_element(By.XPATH,'//*[@id=\"gdasContentsArea\"]/div/div[7]/'+'a['+str(i)+']')\n",
    "                            except:\n",
    "                                page_box = driver.find_element(By.XPATH,'//*[@id=\"gdasContentsArea\"]/div/div[8]/'+'a['+str(i)+']')\n",
    "                            page_box.click()\n",
    "                        except:\n",
    "                            pass\n",
    "                \n",
    "                else: # 마지막페이지의 경우 (넘어가기 인덱스 삭제)\n",
    "                    for i in range(2, page_limit%10+2):\n",
    "                        tmp_list=real_crawling()\n",
    "                        review_list.extend(tmp_list)\n",
    "                        time.sleep(1)\n",
    "                        try:\n",
    "                            if i!=page_limit%10+1:\n",
    "                                try: # 제품마다 xpath값에 차이가 있어서 구분함\n",
    "                                    page_box = driver.find_element(By.XPATH,'//*[@id=\"gdasContentsArea\"]/div/div[7]/'+'a['+str(i)+']')\n",
    "                                except:\n",
    "                                    page_box = driver.find_element(By.XPATH,'//*[@id=\"gdasContentsArea\"]/div/div[8]/'+'a['+str(i)+']')\n",
    "                                page_box.click() \n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "        review_user_df=pd.DataFrame(review_list, columns=['user_name','user_url'])\n",
    "        \n",
    "        product_review_df=pd.concat([product_review_df, review_user_df])\n",
    "    product_review_df.reset_index(inplace=True, drop=True) # 인덱스 초기화    \n",
    "    \n",
    "    return product_review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling(product_df):\n",
    "    product_review_df = pd.DataFrame()  # Initialize the DataFrame to store all reviews\n",
    "\n",
    "    for d in tqdm(range(len(product_df))):\n",
    "        product_name = product_df.iloc[d]['product_name']\n",
    "        url = product_df.iloc[d]['product_url']\n",
    "        driver.get(url)\n",
    "        time.sleep(1.5)\n",
    "\n",
    "\n",
    "        # 리뷰 버튼 클릭\n",
    "        try:\n",
    "            driver.find_element(By.ID, value=\"reviewInfo\").click()\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"{product_name} 상품의 리뷰 버튼 클릭 오류: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 체크박스 해제 (필요시 클릭)\n",
    "        try:\n",
    "            checkbox = driver.find_element(By.ID, 'searchType_3')\n",
    "            if checkbox.is_selected():  # 체크되어 있으면 해제\n",
    "                checkbox.click()\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"{product_name} 상품의 체크박스 해제 오류: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Save the review count\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        review_cnt = int(soup.select('.goods_reputation')[0].text.split('(')[1].split(')')[0].replace(',', ''))\n",
    "        \n",
    "        # List to hold reviews for the current product\n",
    "        review_list = []\n",
    "\n",
    "        # If there are no reviews, continue to the next product\n",
    "        if review_cnt == 0:\n",
    "            continue\n",
    "        \n",
    "        # If there are a lot of reviews\n",
    "        elif review_cnt >= 1000:\n",
    "            for j in range(0, 9):  # Iterate through the pages\n",
    "                if j == 0:  # For the first page\n",
    "                    for i in range(1, 11):  # Pages 1 to 10\n",
    "                        tmp_list = real_crawling()\n",
    "                        review_list.extend(tmp_list)\n",
    "                        time.sleep(1)\n",
    "                        try:\n",
    "                            # Attempt to click on the pagination buttons\n",
    "                            page_box = driver.find_element(By.XPATH, f'//*[@id=\"gdasContentsArea\"]/div/div[7]/a[{i}]')\n",
    "                            page_box.click()\n",
    "                        except:\n",
    "                            # Try the alternate pagination if the first fails\n",
    "                            try:\n",
    "                                page_box = driver.find_element(By.XPATH, f'//*[@id=\"gdasContentsArea\"]/div/div[8]/a[{i}]')\n",
    "                                page_box.click()\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error clicking on page {i} for product {product_name}: {e}\")\n",
    "                                break\n",
    "\n",
    "                elif j != 9:  # For pages 2 to 10\n",
    "                    for i in range(2, 12):  # Next pages\n",
    "                        tmp_list = real_crawling()\n",
    "                        review_list.extend(tmp_list)\n",
    "                        time.sleep(1)\n",
    "                        try:\n",
    "                            page_box = driver.find_element(By.XPATH, f'//*[@id=\"gdasContentsArea\"]/div/div[7]/a[{i}]')\n",
    "                            page_box.click()\n",
    "                        except:\n",
    "                            try:\n",
    "                                page_box = driver.find_element(By.XPATH, f'//*[@id=\"gdasContentsArea\"]/div/div[8]/a[{i}]')\n",
    "                                page_box.click()\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error clicking on page {i} for product {product_name}: {e}\")\n",
    "                                break\n",
    "                \n",
    "                else:  # For the last page\n",
    "                    for i in range(2, 11):\n",
    "                        tmp_list = real_crawling()\n",
    "                        review_list.extend(tmp_list)\n",
    "                        time.sleep(1)\n",
    "                        try:\n",
    "                            if i != 10:  # Skip clicking on the last page link\n",
    "                                page_box = driver.find_element(By.XPATH, f'//*[@id=\"gdasContentsArea\"]/div/div[7]/a[{i}]')\n",
    "                                page_box.click()\n",
    "                        except:\n",
    "                            try:\n",
    "                                page_box = driver.find_element(By.XPATH, f'//*[@id=\"gdasContentsArea\"]/div/div[8]/a[{i}]')\n",
    "                                page_box.click()\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error clicking on page {i} for product {product_name}: {e}\")\n",
    "                                break\n",
    "\n",
    "        else:  # If the number of reviews is less than 1000\n",
    "            page_limit = math.ceil(review_cnt / 10)\n",
    "            next_page_cnt = page_limit // 10\n",
    "            \n",
    "            for j in range(0, next_page_cnt + 1):\n",
    "                if j == 0:  # For the first page\n",
    "                    for i in range(1, 11):\n",
    "                        tmp_list = real_crawling()\n",
    "                        review_list.extend(tmp_list)\n",
    "                        time.sleep(1)\n",
    "                        try:\n",
    "                            page_box = driver.find_element(By.XPATH, f'//*[@id=\"gdasContentsArea\"]/div/div[7]/a[{i}]')\n",
    "                            page_box.click()\n",
    "                        except:\n",
    "                            try:\n",
    "                                page_box = driver.find_element(By.XPATH, f'//*[@id=\"gdasContentsArea\"]/div/div[8]/a[{i}]')\n",
    "                                page_box.click()\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error clicking on page {i} for product {product_name}: {e}\")\n",
    "                                break\n",
    "\n",
    "                elif j != next_page_cnt:  # Not the first or last page\n",
    "                    for i in range(2, 12):\n",
    "                        tmp_list = real_crawling()\n",
    "                        review_list.extend(tmp_list)\n",
    "                        time.sleep(1)\n",
    "                        try:\n",
    "                            page_box = driver.find_element(By.XPATH, f'//*[@id=\"gdasContentsArea\"]/div/div[7]/a[{i}]')\n",
    "                            page_box.click()\n",
    "                        except:\n",
    "                            try:\n",
    "                                page_box = driver.find_element(By.XPATH, f'//*[@id=\"gdasContentsArea\"]/div/div[8]/a[{i}]')\n",
    "                                page_box.click()\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error clicking on page {i} for product {product_name}: {e}\")\n",
    "                                break\n",
    "\n",
    "                else:  # Last page handling\n",
    "                    for i in range(2, page_limit % 10 + 2):\n",
    "                        tmp_list = real_crawling()\n",
    "                        review_list.extend(tmp_list)\n",
    "                        time.sleep(1)\n",
    "                        try:\n",
    "                            if i != page_limit % 10 + 1:\n",
    "                                page_box = driver.find_element(By.XPATH, f'//*[@id=\"gdasContentsArea\"]/div/div[7]/a[{i}]')\n",
    "                                page_box.click()\n",
    "                        except:\n",
    "                            try:\n",
    "                                page_box = driver.find_element(By.XPATH, f'//*[@id=\"gdasContentsArea\"]/div/div[8]/a[{i}]')\n",
    "                                page_box.click()\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error clicking on page {i} for product {product_name}: {e}\")\n",
    "                                break\n",
    "\n",
    "        # Create DataFrame for the current product's reviews\n",
    "        review_user_df = pd.DataFrame(review_list, columns=['user_name', 'user_url'])\n",
    "        \n",
    "        # Concatenate the current product reviews to the overall DataFrame\n",
    "        product_review_df = pd.concat([product_review_df, review_user_df])\n",
    "\n",
    "    product_review_df.reset_index(inplace=True, drop=True)  # Reset the index of the final DataFrame    \n",
    "    \n",
    "    return product_review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1=product_df[:10]\n",
    "df2=product_df[10:20]\n",
    "df3=product_df[20:30]\n",
    "df4=product_df[30:40]\n",
    "df5=product_df[40:50]\n",
    "df6=product_df[50:60]\n",
    "df7=product_df[60:70]\n",
    "df8=product_df[70:80]\n",
    "df9=product_df[80:90]\n",
    "df10=product_df[90:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'By' has no attribute 'element_to_be_clickable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# driver=webdriver.Chrome()\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# product_review_df1=crawling(df1)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# product_review_df1.to_csv('user_data/product_review_df1.csv', index=False)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m product_review_df2\u001b[38;5;241m=\u001b[39m\u001b[43mcrawling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m product_review_df2\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_data/product_review_df2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m product_review_df3\u001b[38;5;241m=\u001b[39mcrawling(df3)\n",
      "Cell \u001b[0;32mIn[73], line 11\u001b[0m, in \u001b[0;36mcrawling\u001b[0;34m(product_df)\u001b[0m\n\u001b[1;32m      8\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1.5\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Click on the review button\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m WebDriverWait(driver, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement_to_be_clickable\u001b[49m((By\u001b[38;5;241m.\u001b[39mID, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewInfo\u001b[39m\u001b[38;5;124m'\u001b[39m)))\u001b[38;5;241m.\u001b[39mclick()\n\u001b[1;32m     12\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Try to uncheck the checkbox (or click the checkbox if needed)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'By' has no attribute 'element_to_be_clickable'"
     ]
    }
   ],
   "source": [
    "# driver=webdriver.Chrome()\n",
    "# product_review_df1=crawling(df1)\n",
    "\n",
    "# product_review_df1.to_csv('user_data/product_review_df1.csv', index=False)\n",
    "\n",
    "product_review_df2=crawling(df2)\n",
    "product_review_df2.to_csv('user_data/product_review_df2.csv', index=False)\n",
    "\n",
    "product_review_df3=crawling(df3)\n",
    "product_review_df3.to_csv('user_data/product_review_df3.csv', index=False)\n",
    "\n",
    "product_review_df4=crawling(df4)\n",
    "product_review_df4.to_csv('user_data/product_review_df4.csv', index=False)\n",
    "\n",
    "product_review_df5=crawling(df5)\n",
    "product_review_df5.to_csv('user_data/product_review_df5.csv', index=False)\n",
    "\n",
    "product_review_df6=crawling(df6)\n",
    "product_review_df6.to_csv('user_data/product_review_df6.csv', index=False)\n",
    "\n",
    "product_review_df10=crawling(df10)\n",
    "product_review_df10.to_csv('user_data/product_review_df10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>별향</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/mypage/getR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>리리578</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/mypage/getR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yop</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/mypage/getR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yop</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/mypage/getR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>띠링띠링띠로링</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/mypage/getR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>올영충성고객</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/mypage/getR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>씩씩한부엉이</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/mypage/getR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>엠마스톤</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/mypage/getR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6360</th>\n",
       "      <td>보노쩡이</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/mypage/getR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6361</th>\n",
       "      <td>푸글렛</td>\n",
       "      <td>https://www.oliveyoung.co.kr/store/mypage/getR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6362 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_name                                           user_url\n",
       "0           별향  https://www.oliveyoung.co.kr/store/mypage/getR...\n",
       "1        리리578  https://www.oliveyoung.co.kr/store/mypage/getR...\n",
       "2          yop  https://www.oliveyoung.co.kr/store/mypage/getR...\n",
       "3          yop  https://www.oliveyoung.co.kr/store/mypage/getR...\n",
       "4      띠링띠링띠로링  https://www.oliveyoung.co.kr/store/mypage/getR...\n",
       "...        ...                                                ...\n",
       "6357    올영충성고객  https://www.oliveyoung.co.kr/store/mypage/getR...\n",
       "6358    씩씩한부엉이  https://www.oliveyoung.co.kr/store/mypage/getR...\n",
       "6359      엠마스톤  https://www.oliveyoung.co.kr/store/mypage/getR...\n",
       "6360      보노쩡이  https://www.oliveyoung.co.kr/store/mypage/getR...\n",
       "6361       푸글렛  https://www.oliveyoung.co.kr/store/mypage/getR...\n",
       "\n",
       "[6362 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_review_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = sorted(glob(\"user_data/*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=pd.DataFrame()\n",
    "for i in range(0, len(df_list)):\n",
    "    tmp=pd.read_csv(df_list[i])\n",
    "    total=pd.concat([total, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.shape[0], total.user_url.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total=total.groupby(['user_name','user_url']).count()\n",
    "total.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=pd.read_csv('total.csv')\n",
    "user_list=list(total['user_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_review_crawling(user_list):\n",
    "    review_data=pd.DataFrame()\n",
    "    for i in tqdm(user_list):\n",
    "        url = i\n",
    "        driver.get(url)\n",
    "        \n",
    "        # 프로필 비공개한 유저 pass\n",
    "        html = driver.page_source\n",
    "        soup3 = BeautifulSoup(html, 'html.parser')\n",
    "        rv_num = soup3.find('div', {\"class\":\"reviewer-profile-content__header\"})   \n",
    "        if str(type(rv_num))==\"<class 'bs4.element.Tag'>\" and rv_num.select('div>span')[0].text.strip()!='-':\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(1)  # 로딩을 기다립니다.\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            html = driver.page_source\n",
    "            soup3 = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            # 리뷰어 이름\n",
    "            rv_name = soup3.select('.id.my-profile.on>strong')   # [Ctrl + Shift + I]로 코드 확인 가능\n",
    "            for info in rv_name:\n",
    "              rv_name=info.get_text().strip()\n",
    "\n",
    "            # 리뷰어 랭킹\n",
    "            rv_rank = soup3.find_all('span', {\"class\":\"badge-item top-number\"})   # [Ctrl + Shift + I]로 코드 확인 가능\n",
    "            for info in rv_rank:\n",
    "              rv_rank=info.get_text().strip()\n",
    "\n",
    "            # 리뷰어 피부타입\n",
    "            rv_type = soup3.find_all('li', {\"class\":\"list-item\"})   # [Ctrl + Shift + I]로 코드 확인 가능\n",
    "            type_list=[]\n",
    "            for info in rv_type:\n",
    "              type_list.append(info.get_text().strip())\n",
    "\n",
    "            # 리뷰어 도움/팔로워/팔로잉 \n",
    "            help_num=int(soup3.select('.reviewer-profile-info__bottom.reviewer-data-info>.reviewer-data-info__list')[0].select('.num')[0].text.strip().replace(',',''))\n",
    "            follower_num=int(soup3.select('.reviewer-profile-info__bottom.reviewer-data-info>.reviewer-data-info__list')[1].select('.num')[0].text.strip().replace(',',''))\n",
    "            following_num=int(soup3.select('.reviewer-profile-info__bottom.reviewer-data-info>.reviewer-data-info__list')[2].select('.num')[0].text.strip().replace(',',''))\n",
    "\n",
    "            # 리뷰어 누적 리뷰수 → 문제 있음(필요없는 부분 있음)\n",
    "            rv_num = soup3.find('div', {\"class\":\"reviewer-profile-content__header\"})   # [Ctrl + Shift + I]로 코드 확인 가능\n",
    "            rv_num=rv_num.select('div>span')[0].text.strip()\n",
    "\n",
    "            reviews=soup3.select('.rw-box')\n",
    "            review_info=[]\n",
    "            for review in reviews:\n",
    "                brand=review.select('.rw-box-figcaption__brand') # 브랜드\n",
    "                for info in brand:\n",
    "                    brand=info.text.strip()\n",
    "\n",
    "                product_name=review.select('.rw-box-figcaption__name') #제품 이름\n",
    "                for info in product_name:\n",
    "                    product_name=info.text\n",
    "\n",
    "                product_option=review.select('.rw-box-figcaption__sub') # 제품 옵션\n",
    "                for info in product_option:\n",
    "                  product_option=info.text.strip()\n",
    "\n",
    "                review_point=review.select('.point')[0].text.strip() #리뷰 평점\n",
    "                review_date=review.select('.review_point_text')[0].text.strip() #리뷰 작성일 \n",
    "                review_text=review.select('.rw-box__description')[0].text.strip() #리뷰 내용\n",
    "                review_referral=int(review.select('.rw-box__help .num')[0].text.strip()) #리뷰 추천수\n",
    "                review_info.append([brand,product_name, product_option, review_point, review_date, review_text, review_referral])\n",
    "\n",
    "            review_df=pd.DataFrame(review_info, columns=['brand','product_name','product_option','review_point','review_date','review_text','review_referral'])\n",
    "\n",
    "            review_df['user_name']=rv_name\n",
    "            review_df['user_rank']=str(rv_rank)\n",
    "            review_df['user_type']=str(type_list)\n",
    "            review_df['user_help_num']=help_num\n",
    "            review_df['user_follower_num']=follower_num\n",
    "            review_df['user_following_num']=following_num\n",
    "            \n",
    "            review_data=pd.concat([review_data, review_df])\n",
    "    return review_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_list1_1=user_list[:500]\n",
    "user_list1_2=user_list[500:1500]\n",
    "user_list1_3=user_list[1500:4000]\n",
    "user_list2=user_list[4000:8000]\n",
    "user_list3=user_list[8000:12000]\n",
    "user_list4=user_list[12000:16000]\n",
    "user_list5=user_list[16000:20000]\n",
    "user_list6=user_list[20000:24000]\n",
    "user_list7=user_list[24000:28000]\n",
    "user_list8=user_list[28000:32000]\n",
    "user_list9=user_list[32000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.oliveyoung.co.kr/store/goods/getGoodsDetail.do?goodsNo=A000000211001&dispCatNo=90000010009&trackingCd=Best_Sellingbest&t_page=랭킹&t_click=판매랭킹_전체_상품상세&t_number=1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_data1_2=user_review_crawling(user_list1_2)\n",
    "review_data1_2.reset_index(inplace=True, drop=True)\n",
    "review_data1_2.to_csv('user_review_data/review_data1_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv_prc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
